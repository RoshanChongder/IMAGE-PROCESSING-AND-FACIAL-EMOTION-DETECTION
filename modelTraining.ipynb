{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelTraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "160LeSnO0EpcaQEZFwFuHXU7iePbPwb5B",
      "authorship_tag": "ABX9TyPPdU3+LhrBVLLFPwWPPDBQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshanChongder/IMAGE-PROCESSING-AND-ONLINE-RECOMMENDATION-OF-PRODUCTS-USING-ARTIFICIAL-INTELLIGENCE-TECHNIQUES/blob/master/modelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHbjiJ3emIQK"
      },
      "source": [
        "To Mount Google Drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veJuAiGEVQCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed696c3c-4eb0-4c5f-d11d-09a62d9e6084"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urBA-HZCfGhQ"
      },
      "source": [
        "Importing required Modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyFDerYCfJ7J"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# keras is free source deep learning library in python\n",
        "# from this library different layer will be imported\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stRhs7HuEbha"
      },
      "source": [
        "Downloading the csv file from the mounted google drive "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "354Xe42eYugK"
      },
      "source": [
        "Importing the data set and pre-viewing  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzifmEiiY1X7",
        "outputId": "4433b9de-eb2b-4995-94b6-aeddc560b518"
      },
      "source": [
        "# Method to read CSV Files\n",
        "def read_CSV( path ):\n",
        "    try:\n",
        "        file = pd.read_csv( path )\n",
        "        return file\n",
        "    except FileNotFoundError:\n",
        "        print( \"CSV File not found at \" + path )\n",
        "        return None\n",
        "    except Exception:\n",
        "        print(\" Unknown error appeared \")\n",
        "        return None\n",
        "\n",
        "# reading the csv file \n",
        "\n",
        "data_set = read_CSV('drive/MyDrive/EmotionDetection/fer2013/fer2013.csv') \n",
        "print( data_set.info() ) # checking info of the data set \n",
        "print( data_set.head())  # showing the first ew line of the data set \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35887 entries, 0 to 35886\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   emotion  35887 non-null  int64 \n",
            " 1   pixels   35887 non-null  object\n",
            " 2   Usage    35887 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 841.2+ KB\n",
            "None\n",
            "   emotion                                             pixels     Usage\n",
            "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
            "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
            "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
            "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
            "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gluCxUCBtrID"
      },
      "source": [
        "Now , as the data set is loaded , we will just extract the data from the csv file and tehn load then in  train , ytrain , xtest and ytest "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90yZ2Limt2TZ",
        "outputId": "7a263a51-12cb-4446-d9f8-428853286345"
      },
      "source": [
        "# Addition of data into list from CSV for training and public testing\n",
        "def data_Addition() :\n",
        "    global x_train , y_train , x_test , y_test , data_set\n",
        "    d = {3:0} \n",
        "    for row_count,row in data_set.iterrows():\n",
        "        #if row['emotion'] in [1,2] or ( d[3]>5800 and row['emotion']==3 and row['Usage'] == 'Training' ) :  continue \n",
        "        \n",
        "        \n",
        "        if row['emotion'] in [1,2] or ( row['emotion'] == 3  and d[ row['emotion'] ] > 4000  and row['Usage'] == 'Training' ) : continue \n",
        "        value = row['pixels'].split(' ')   # extracting the pixels as a list\n",
        "        try :\n",
        "            if 'Training' in row['Usage'] :        # if the current column is for Training\n",
        "                x_train.append(np.array(value,'float32'))        # adding the pixels in the x axis\n",
        "                y_train.append(row['emotion'])\n",
        "\n",
        "\n",
        "                if row['emotion'] in d :\n",
        "                    d[ row['emotion'] ]+=1\n",
        "                else :\n",
        "                    d[ row['emotion'] ] = 1 \n",
        "\n",
        "\n",
        "                #{3: 5801, 0: 3995, 4: 4830, 6: 4965, 5: 3171}\n",
        "                # added this to restrict some of the happy data - ( d[3]>5800 and row['emotion']==3 and row['Usage'] == 'Training' ) \n",
        "\n",
        "            # adding emotion in the y axis\n",
        "            # elif 'PublicTest' in row['Usage']:    # if the current column is for testing\n",
        "            #     x_test.append(np.array( value,'float32'))\n",
        "            #     y_test.append( row['emotion'])\n",
        "\n",
        "                # {0: 467, 4: 653, 6: 607, 3: 895, 5: 415}\n",
        "            else : \n",
        "                # also including the private test set  over here \n",
        "                x_test.append(np.array( value,'float32'))\n",
        "                y_test.append( row['emotion']) \n",
        "\n",
        "                # {0: 958, 4: 1247, 6: 1233, 3: 1774, 5: 831}  # Testing :  6043 \n",
        "\n",
        "        except:\n",
        "            print(\" Error occurred at row number \" + row_count)\n",
        "            print(\"Data Set in that row is \" + row )\n",
        "\n",
        "    print(d)\n",
        "\n",
        "# Now we will do training and public testing\n",
        "\n",
        "x_train , y_train = [] , []   # data the will be used for training will added in this two lists\n",
        "x_test , y_test = [] , []     # data that will be used for public testing will be added here\n",
        "\n",
        "data_Addition()    # addition of data in the lists for training and testing\n",
        "\n",
        "print( \"Training : \" , len(x_train) , \"Testing : \" , len(x_test) )\n",
        "\n",
        "# checking the lists\n",
        "print( x_train[:2])\n",
        "print( y_train[:2])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{3: 4001, 0: 3995, 4: 4830, 6: 4965, 5: 3171}\n",
            "Training :  20962 Testing :  6043\n",
            "[array([ 70.,  80.,  82., ..., 106., 109.,  82.], dtype=float32), array([151., 150., 147., ..., 193., 183., 184.], dtype=float32)]\n",
            "[0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0LndI84mcTI"
      },
      "source": [
        "Don't execute the next as it is the copy of the previous code cell "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ3Vac4qmnXs",
        "outputId": "72c2fc65-708b-414c-9f81-2835f8789346"
      },
      "source": [
        "# Addition of data into list from CSV for training and public testing\n",
        "'''\n",
        "def data_Addition() :\n",
        "    global x_train , y_train , x_test , y_test , data_set\n",
        "    d = dict()\n",
        "\n",
        "    for row_count,row in data_set.iterrows():\n",
        "        if row['emotion'] in [1,2] :  continue \n",
        "        value = row['pixels'].split(' ')   # extracting the pixels as a list\n",
        "        try :\n",
        "            if 'Training' in row['Usage'] :        # if the current column is for Training\n",
        "                x_train.append(np.array(value,'float32'))        # adding the pixels in the x axis\n",
        "                y_train.append(row['emotion'])\n",
        "                \n",
        "                if row['emotion'] in d :\n",
        "                    d[ row['emotion'] ]+=1\n",
        "                else :\n",
        "                    d[ row['emotion'] ] = 1 \n",
        "            \n",
        "            # adding emotion in the y axis\n",
        "            elif 'PublicTest' in row['Usage']:    # if the current column is for testing\n",
        "                x_test.append(np.array( value,'float32'))\n",
        "                y_test.append( row['emotion'])\n",
        "\n",
        "        except:\n",
        "            print(\" Error occurred at row number \" + row_count)\n",
        "            print(\"Data Set in that row is \" + row )\n",
        "\n",
        "    print(d )\n",
        "\n",
        "# Now we will do training and public testing\n",
        "\n",
        "x_train , y_train = [] , []   # data the will be used for training will added in this two lists\n",
        "x_test , y_test = [] , []     # data that will be used for public testing will be added here\n",
        "\n",
        "data_Addition()    # addition of data in the lists for training and testing\n",
        "\n",
        "# checking the lists\n",
        "#print( x_train[:2])\n",
        "#print( y_train[:2])\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 3995, 4: 4830, 6: 4965, 3: 7215, 5: 3171}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqgWrDBnuynx"
      },
      "source": [
        "As the keras module only takes numpy array as input parameters , we need to convert the lists into numpy arrays ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgIo-D7ivIHX",
        "outputId": "961fec78-0c2b-4ea5-9ce3-0b5f23db1ea2"
      },
      "source": [
        "# Method to Convert from list to Numpy Arrays\n",
        "def Convert_to_np_Array():\n",
        "    global x_train, x_test, y_test , y_train\n",
        "    # Converting list to numpy Array\n",
        "    x_train = np.array(x_train, 'float32')\n",
        "    y_train = np.array(y_train, 'float32')\n",
        "    x_test = np.array(x_test, 'float32')\n",
        "    y_test = np.array(y_test, 'float32')\n",
        "\n",
        "\n",
        "\n",
        "# As the Keras Module only takes numpy arrays as input\n",
        "# we need to convert this lists into numpy arrays\n",
        "\n",
        "Convert_to_np_Array()\n",
        "print( type(x_train) )  # checking if the type has changed to numpy or not \n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLkmI8P1GNte"
      },
      "source": [
        "Resaclling of x_train and y_train and then reshaping them into one d array \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRvUpQEcGRhU",
        "outputId": "a6ec293a-1d11-4427-c6db-16551517a349"
      },
      "source": [
        "def Rescale():\n",
        "    # Normalizing the data\n",
        "    # why data normalization is required - https://www.import.io/post/what-is-data-normalization-and-why-is-it-important/\n",
        "    # how it's work - https://www.educative.io/edpresso/data-normalization-in-python\n",
        "    # read Out - https://www.mathsisfun.com/data/standard-deviation.html\n",
        "\n",
        "    global x_train , x_test , y_test , y_train\n",
        "\n",
        "    # we are basically rescaling\n",
        "    x_train -= np.mean(x_train, axis=0)\n",
        "    x_train /= np.std(x_train, axis=0)  # CENTRALIZING THE DATA\n",
        "\n",
        "    x_test -= np.mean(x_test, axis=0)\n",
        "    x_test /= np.std(x_test, axis=0)\n",
        "\n",
        "\n",
        "def Reshape( width , height ):\n",
        "\n",
        "    global x_train , y_train , x_test , y_test\n",
        "\n",
        "    x_train = x_train.reshape(x_train.shape[0], width, height, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], width, height, 1)\n",
        "    # WHAT THIS FUNCTION DOES TO_CATEGORICAL\n",
        "    y_train = np_utils.to_categorical(y_train,num_classes=7)\n",
        "    y_test = np_utils.to_categorical(y_test,num_classes=7)\n",
        "    \n",
        "    print( ' Reshape method is called  ')\n",
        "\n",
        "# Rescalling the data\n",
        "Rescale()\n",
        "\n",
        "# Reshaping the x train and y train in to a one d array\n",
        "Reshape(48,48)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Reshape method is called  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAysuHTmG5Gs"
      },
      "source": [
        "Now the main comes - designing the CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89pfeVebG8cm",
        "outputId": "e42f322b-e339-4c22-dba8-45a76899b4da"
      },
      "source": [
        "\n",
        "def Design_CNN():\n",
        "\n",
        "    # The number of epochs is a hyperparameter\n",
        "    # that defines the number times that the learning algorithm will work through the entire training dataset\n",
        "    features = 64\n",
        "    Batch_size = 64\n",
        "    Label = 7\n",
        "    epoch = 100\n",
        "    global  x_train, y_train\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "\n",
        "    ## Layer 1\n",
        "\n",
        "    # adding layers\n",
        "    # Conv2d is used as the image are in 2d format\n",
        "\n",
        "    # here we are trying extract input\n",
        "    # Relu is a rectifier\n",
        "\n",
        "    # Search Kernal size\n",
        "    model.add(Conv2D(features,kernel_size=(3,3),activation='relu',input_shape=(x_train.shape[1:])))\n",
        "    model.add(Conv2D(features,kernel_size=(3, 3),activation='relu'))\n",
        "\n",
        "    # adding a max pooling 2D layer\n",
        "    # It mainly helps to control over fitting\n",
        "    # can use average pooling layer also\n",
        "    model.add( MaxPool2D(pool_size=(2,2),strides=(2,2)) )\n",
        "\n",
        "    # adding a drop out layer\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    ## 2ND layer\n",
        "    model.add(Conv2D(features, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(Conv2D(features, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    ## 3RD Layer\n",
        "    model.add(Conv2D(2*features, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(Conv2D(2*features, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "    # What is drop out layer\n",
        "\n",
        "    model.add( Flatten() )\n",
        "\n",
        "    # adding dense layers\n",
        "    model.add(Dense(2**3 * features, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(2 ** 3 * features, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Adding the final layers\n",
        "    model.add(Dense(Label,activation='softmax')) # Activation is softmax as we want to bind in the 7 labels of 0ptions\n",
        "\n",
        "    model.compile(loss=categorical_crossentropy,optimizer=Adam(),metrics=['accuracy'])\n",
        "    model.fit(x_train,y_train,batch_size=Batch_size,epochs=epoch,verbose=1,validation_data=(x_test,y_test), shuffle=True )\n",
        "\n",
        "\n",
        "    # Saving the model\n",
        "\n",
        "    EmotionDetectJson = model.to_json()\n",
        "    with open(\"fer.json\",\"w\") as file :\n",
        "        file.write(EmotionDetectJson)\n",
        "    model.save_weights(\"fer.h5\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Start designing Our CNN\n",
        "\n",
        "# To build the model we will be using sequential Type\n",
        "\n",
        "Design_CNN()\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "328/328 [==============================] - 52s 25ms/step - loss: 1.6031 - accuracy: 0.2520 - val_loss: 1.3736 - val_accuracy: 0.4195\n",
            "Epoch 2/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 1.3463 - accuracy: 0.4164 - val_loss: 1.1588 - val_accuracy: 0.5251\n",
            "Epoch 3/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 1.1648 - accuracy: 0.5175 - val_loss: 1.0794 - val_accuracy: 0.5694\n",
            "Epoch 4/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 1.0708 - accuracy: 0.5710 - val_loss: 0.9933 - val_accuracy: 0.5999\n",
            "Epoch 5/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 1.0176 - accuracy: 0.5894 - val_loss: 0.9735 - val_accuracy: 0.6088\n",
            "Epoch 6/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.9515 - accuracy: 0.6191 - val_loss: 0.9216 - val_accuracy: 0.6402\n",
            "Epoch 7/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.9292 - accuracy: 0.6289 - val_loss: 0.8887 - val_accuracy: 0.6518\n",
            "Epoch 8/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.8841 - accuracy: 0.6487 - val_loss: 0.8952 - val_accuracy: 0.6485\n",
            "Epoch 9/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.8655 - accuracy: 0.6599 - val_loss: 0.8840 - val_accuracy: 0.6523\n",
            "Epoch 10/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.8349 - accuracy: 0.6706 - val_loss: 0.8734 - val_accuracy: 0.6583\n",
            "Epoch 11/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.8050 - accuracy: 0.6835 - val_loss: 0.8803 - val_accuracy: 0.6553\n",
            "Epoch 12/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.7826 - accuracy: 0.6917 - val_loss: 0.9039 - val_accuracy: 0.6548\n",
            "Epoch 13/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.7697 - accuracy: 0.6991 - val_loss: 0.8709 - val_accuracy: 0.6642\n",
            "Epoch 14/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.7385 - accuracy: 0.7079 - val_loss: 0.8905 - val_accuracy: 0.6651\n",
            "Epoch 15/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.7322 - accuracy: 0.7071 - val_loss: 0.8979 - val_accuracy: 0.6598\n",
            "Epoch 16/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.7110 - accuracy: 0.7198 - val_loss: 0.9369 - val_accuracy: 0.6502\n",
            "Epoch 17/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.6983 - accuracy: 0.7220 - val_loss: 0.9444 - val_accuracy: 0.6580\n",
            "Epoch 18/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.6720 - accuracy: 0.7385 - val_loss: 0.9216 - val_accuracy: 0.6618\n",
            "Epoch 19/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.6587 - accuracy: 0.7430 - val_loss: 0.9165 - val_accuracy: 0.6621\n",
            "Epoch 20/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.6375 - accuracy: 0.7549 - val_loss: 0.9163 - val_accuracy: 0.6669\n",
            "Epoch 21/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.6200 - accuracy: 0.7548 - val_loss: 0.9642 - val_accuracy: 0.6675\n",
            "Epoch 22/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.6165 - accuracy: 0.7555 - val_loss: 0.9516 - val_accuracy: 0.6710\n",
            "Epoch 23/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.5952 - accuracy: 0.7673 - val_loss: 0.9392 - val_accuracy: 0.6740\n",
            "Epoch 24/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.5815 - accuracy: 0.7740 - val_loss: 0.9569 - val_accuracy: 0.6664\n",
            "Epoch 25/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.5830 - accuracy: 0.7710 - val_loss: 0.9492 - val_accuracy: 0.6656\n",
            "Epoch 26/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.5686 - accuracy: 0.7789 - val_loss: 0.9579 - val_accuracy: 0.6656\n",
            "Epoch 27/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.5414 - accuracy: 0.7904 - val_loss: 0.9864 - val_accuracy: 0.6672\n",
            "Epoch 28/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.5282 - accuracy: 0.7992 - val_loss: 1.0022 - val_accuracy: 0.6664\n",
            "Epoch 29/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.5439 - accuracy: 0.7908 - val_loss: 1.0708 - val_accuracy: 0.6576\n",
            "Epoch 30/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.5143 - accuracy: 0.8035 - val_loss: 1.0059 - val_accuracy: 0.6613\n",
            "Epoch 31/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.5108 - accuracy: 0.8002 - val_loss: 1.0494 - val_accuracy: 0.6639\n",
            "Epoch 32/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.4938 - accuracy: 0.8115 - val_loss: 1.0247 - val_accuracy: 0.6656\n",
            "Epoch 33/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.4940 - accuracy: 0.8100 - val_loss: 1.0742 - val_accuracy: 0.6623\n",
            "Epoch 34/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.4845 - accuracy: 0.8120 - val_loss: 1.0448 - val_accuracy: 0.6599\n",
            "Epoch 35/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.4778 - accuracy: 0.8139 - val_loss: 1.1478 - val_accuracy: 0.6498\n",
            "Epoch 36/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.4589 - accuracy: 0.8237 - val_loss: 1.0759 - val_accuracy: 0.6536\n",
            "Epoch 37/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.4545 - accuracy: 0.8258 - val_loss: 1.1056 - val_accuracy: 0.6659\n",
            "Epoch 38/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.4464 - accuracy: 0.8276 - val_loss: 1.0957 - val_accuracy: 0.6594\n",
            "Epoch 39/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.4469 - accuracy: 0.8282 - val_loss: 1.0624 - val_accuracy: 0.6652\n",
            "Epoch 40/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.4266 - accuracy: 0.8335 - val_loss: 1.1263 - val_accuracy: 0.6551\n",
            "Epoch 41/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.4270 - accuracy: 0.8347 - val_loss: 1.1453 - val_accuracy: 0.6575\n",
            "Epoch 42/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.4355 - accuracy: 0.8323 - val_loss: 1.1311 - val_accuracy: 0.6636\n",
            "Epoch 43/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.4225 - accuracy: 0.8413 - val_loss: 1.1167 - val_accuracy: 0.6626\n",
            "Epoch 44/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.4052 - accuracy: 0.8486 - val_loss: 1.1519 - val_accuracy: 0.6515\n",
            "Epoch 45/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.4033 - accuracy: 0.8479 - val_loss: 1.1279 - val_accuracy: 0.6626\n",
            "Epoch 46/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3945 - accuracy: 0.8511 - val_loss: 1.1879 - val_accuracy: 0.6652\n",
            "Epoch 47/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.3918 - accuracy: 0.8500 - val_loss: 1.1360 - val_accuracy: 0.6675\n",
            "Epoch 48/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3767 - accuracy: 0.8582 - val_loss: 1.1378 - val_accuracy: 0.6637\n",
            "Epoch 49/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3881 - accuracy: 0.8553 - val_loss: 1.1933 - val_accuracy: 0.6480\n",
            "Epoch 50/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3762 - accuracy: 0.8557 - val_loss: 1.1393 - val_accuracy: 0.6679\n",
            "Epoch 51/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3763 - accuracy: 0.8612 - val_loss: 1.1702 - val_accuracy: 0.6490\n",
            "Epoch 52/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3767 - accuracy: 0.8561 - val_loss: 1.2001 - val_accuracy: 0.6493\n",
            "Epoch 53/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3688 - accuracy: 0.8632 - val_loss: 1.1711 - val_accuracy: 0.6662\n",
            "Epoch 54/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3576 - accuracy: 0.8658 - val_loss: 1.2719 - val_accuracy: 0.6584\n",
            "Epoch 55/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3499 - accuracy: 0.8685 - val_loss: 1.1724 - val_accuracy: 0.6680\n",
            "Epoch 56/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3458 - accuracy: 0.8703 - val_loss: 1.1887 - val_accuracy: 0.6558\n",
            "Epoch 57/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3496 - accuracy: 0.8698 - val_loss: 1.2298 - val_accuracy: 0.6563\n",
            "Epoch 58/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.3434 - accuracy: 0.8745 - val_loss: 1.2670 - val_accuracy: 0.6465\n",
            "Epoch 59/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3495 - accuracy: 0.8716 - val_loss: 1.3188 - val_accuracy: 0.6356\n",
            "Epoch 60/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.3428 - accuracy: 0.8757 - val_loss: 1.2695 - val_accuracy: 0.6609\n",
            "Epoch 61/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3341 - accuracy: 0.8754 - val_loss: 1.2555 - val_accuracy: 0.6604\n",
            "Epoch 62/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.3298 - accuracy: 0.8816 - val_loss: 1.2267 - val_accuracy: 0.6543\n",
            "Epoch 63/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3310 - accuracy: 0.8771 - val_loss: 1.2866 - val_accuracy: 0.6528\n",
            "Epoch 64/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3354 - accuracy: 0.8797 - val_loss: 1.3333 - val_accuracy: 0.6452\n",
            "Epoch 65/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3182 - accuracy: 0.8829 - val_loss: 1.2200 - val_accuracy: 0.6646\n",
            "Epoch 66/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.3030 - accuracy: 0.8869 - val_loss: 1.2775 - val_accuracy: 0.6540\n",
            "Epoch 67/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.3220 - accuracy: 0.8819 - val_loss: 1.2726 - val_accuracy: 0.6576\n",
            "Epoch 68/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.3117 - accuracy: 0.8882 - val_loss: 1.3259 - val_accuracy: 0.6571\n",
            "Epoch 69/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3094 - accuracy: 0.8881 - val_loss: 1.2380 - val_accuracy: 0.6616\n",
            "Epoch 70/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.3134 - accuracy: 0.8860 - val_loss: 1.3094 - val_accuracy: 0.6576\n",
            "Epoch 71/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.3036 - accuracy: 0.8894 - val_loss: 1.3194 - val_accuracy: 0.6626\n",
            "Epoch 72/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.2962 - accuracy: 0.8931 - val_loss: 1.3038 - val_accuracy: 0.6581\n",
            "Epoch 73/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.2891 - accuracy: 0.8905 - val_loss: 1.3113 - val_accuracy: 0.6535\n",
            "Epoch 74/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.2940 - accuracy: 0.8963 - val_loss: 1.2430 - val_accuracy: 0.6631\n",
            "Epoch 75/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.2956 - accuracy: 0.8940 - val_loss: 1.2808 - val_accuracy: 0.6591\n",
            "Epoch 76/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.2894 - accuracy: 0.8953 - val_loss: 1.3061 - val_accuracy: 0.6637\n",
            "Epoch 77/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2910 - accuracy: 0.8995 - val_loss: 1.2827 - val_accuracy: 0.6561\n",
            "Epoch 78/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.2875 - accuracy: 0.8966 - val_loss: 1.2893 - val_accuracy: 0.6487\n",
            "Epoch 79/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2815 - accuracy: 0.9007 - val_loss: 1.3410 - val_accuracy: 0.6604\n",
            "Epoch 80/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2925 - accuracy: 0.8918 - val_loss: 1.3309 - val_accuracy: 0.6457\n",
            "Epoch 81/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2821 - accuracy: 0.8968 - val_loss: 1.4433 - val_accuracy: 0.6455\n",
            "Epoch 82/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.2878 - accuracy: 0.8951 - val_loss: 1.3438 - val_accuracy: 0.6651\n",
            "Epoch 83/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.2841 - accuracy: 0.9025 - val_loss: 1.3534 - val_accuracy: 0.6472\n",
            "Epoch 84/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.2713 - accuracy: 0.9016 - val_loss: 1.3723 - val_accuracy: 0.6536\n",
            "Epoch 85/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2870 - accuracy: 0.8971 - val_loss: 1.3478 - val_accuracy: 0.6566\n",
            "Epoch 86/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2521 - accuracy: 0.9075 - val_loss: 1.3095 - val_accuracy: 0.6568\n",
            "Epoch 87/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2670 - accuracy: 0.9037 - val_loss: 1.3568 - val_accuracy: 0.6616\n",
            "Epoch 88/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2614 - accuracy: 0.9102 - val_loss: 1.2839 - val_accuracy: 0.6553\n",
            "Epoch 89/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.2680 - accuracy: 0.9045 - val_loss: 1.3171 - val_accuracy: 0.6522\n",
            "Epoch 90/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2656 - accuracy: 0.9046 - val_loss: 1.4484 - val_accuracy: 0.6520\n",
            "Epoch 91/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.2764 - accuracy: 0.8980 - val_loss: 1.4335 - val_accuracy: 0.6497\n",
            "Epoch 92/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2691 - accuracy: 0.9043 - val_loss: 1.3671 - val_accuracy: 0.6495\n",
            "Epoch 93/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2725 - accuracy: 0.9038 - val_loss: 1.3456 - val_accuracy: 0.6576\n",
            "Epoch 94/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2596 - accuracy: 0.9063 - val_loss: 1.3079 - val_accuracy: 0.6596\n",
            "Epoch 95/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.2434 - accuracy: 0.9122 - val_loss: 1.3486 - val_accuracy: 0.6618\n",
            "Epoch 96/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.2590 - accuracy: 0.9095 - val_loss: 1.3581 - val_accuracy: 0.6608\n",
            "Epoch 97/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2718 - accuracy: 0.9071 - val_loss: 1.4403 - val_accuracy: 0.6518\n",
            "Epoch 98/100\n",
            "328/328 [==============================] - 6s 20ms/step - loss: 0.2584 - accuracy: 0.9081 - val_loss: 1.2969 - val_accuracy: 0.6528\n",
            "Epoch 99/100\n",
            "328/328 [==============================] - 7s 20ms/step - loss: 0.2556 - accuracy: 0.9121 - val_loss: 1.2792 - val_accuracy: 0.6507\n",
            "Epoch 100/100\n",
            "328/328 [==============================] - 7s 22ms/step - loss: 0.2638 - accuracy: 0.9065 - val_loss: 1.4305 - val_accuracy: 0.6575\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}