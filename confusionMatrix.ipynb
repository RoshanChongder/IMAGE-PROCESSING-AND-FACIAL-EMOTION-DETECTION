{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "confusionMatrix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TyDiXEtBQbXiTcJW9nimin3scA0H9Fjs",
      "authorship_tag": "ABX9TyNINe3vMjigOoS1DqsIiwA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshanChongder/IMAGE-PROCESSING-AND-FACIAL-EMOTION-DETECTION/blob/master/confusionMatrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7saPqm08VH96"
      },
      "source": [
        "First , we will load the trained model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJjM3O46VTGv",
        "outputId": "cad40460-f4d2-48a1-ec3c-130af3125c3a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md3chI-LNfdU"
      },
      "source": [
        "# import the required libraries \n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2 , os , time , html \n",
        "import numpy as np\n",
        "import PIL , io\n",
        "from keras.preprocessing import image\n",
        "from keras.models import model_from_json "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRB1N-yqNnEu",
        "outputId": "208fdf27-050b-4459-aa91-3941030369da"
      },
      "source": [
        "#drive/MyDrive/EmotionDetection/Model_Training_Op/24_06_1/model/\n",
        "model = model_from_json( open('drive/MyDrive/EmotionDetection/Model_Training_Op/24_06/model/fer.json','r').read() )\n",
        "# drive/MyDrive/EmotionDetection/Model_Training_Op/24_06_1/model/\n",
        "model.load_weights( 'drive/MyDrive/EmotionDetection/Model_Training_Op/24_06_1/model/fer.h5' )\n",
        "print('The model is been loadded with weights')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model is been loadded with weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8OdD7LvN92H"
      },
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "  return img\n",
        "\n",
        "\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  bbox_PIL.save(iobuf, format='png') # format bbox into png for return\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))  # format return string\n",
        "\n",
        "  return bbox_bytes\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPphwyLAN-oJ"
      },
      "source": [
        "# Haar Cascade face detection model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs8Wm3DAOCHx"
      },
      "source": [
        "def take_photo( loc , quality=0.8 ):\n",
        "\n",
        "  ''' This method receives a location of an image .\n",
        "  Then it reads the image and then predicts the emotion of \n",
        "  the face present in the image ''' \n",
        "\n",
        "\n",
        "  # read the image from the drive location that is passed \n",
        "  img = cv2.imread( loc , cv2.IMREAD_COLOR )\n",
        "  \n",
        "  # convertion to grayscale \n",
        "  gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  #print(gray_img.shape)\n",
        "\n",
        "  # get face bounding box coordinates using Haar Cascade\n",
        "  faces = face_cascade.detectMultiScale(gray_img)\n",
        "  \n",
        "  # create transparent overlay for bounding box\n",
        "  bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "  \n",
        "  predicted = []\n",
        "\n",
        "  # draw face bounding box on image\n",
        "  for (x,y,w,h) in faces:\n",
        "\n",
        "      img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) # placing the rectangle around the face \n",
        "      cropped_gray = gray_img[y:y+w,x:x+h]  # cropping the face from the image \n",
        "      cropped_gray = cv2.resize(cropped_gray,(48,48)) # resizing the image \n",
        "      img_pixels = image.img_to_array(cropped_gray)  # getting the image pixeles into array \n",
        "      img_pixels = np.expand_dims(img_pixels, axis = 0) # expanding dim \n",
        "      img_pixels /= 255\n",
        "\n",
        "      predictions = model.predict(img_pixels)  # predicting \n",
        "        #print( predictions )\n",
        "        #find max indexed array\n",
        "      index = np.argmax(predictions[0]) \n",
        "        \n",
        "      emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "      predicted_emotion = emotions[index]  \n",
        "      predicted.append( index  )\n",
        "      #print( predicted_emotion )\n",
        "      cv2.putText( img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        " \n",
        "  return [ img , predicted ]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywNuhNuqOPZo",
        "outputId": "9b829201-dc0f-49b2-9d01-746c0c44112b"
      },
      "source": [
        "# from where all the images will be read \n",
        "directory = 'drive/MyDrive/EmotionDetection/Model_Training_Op/images'   \n",
        "\n",
        "# d is for directory refference and tag  \n",
        "# actual and pre will store actual emotion and predicted emotion \n",
        "d , actual , pre = { \"angry\" : 0 , \"happy\" : 3 , \"sad\" : 4 , \"surprise\" : 5 , \"neutral\" : 6 } , [] , [] \n",
        "\n",
        "for dir in os.listdir(directory) : \n",
        "  tag = None \n",
        "  \n",
        "  if dir in d :\n",
        "    tag = d[dir]  # getting the tag correspondin to the dir  \n",
        "  else :\n",
        "    print( dir , \" not found in \" , d )\n",
        "    break \n",
        "\n",
        "  subdir = os.path.join( directory, dir ) # selecting a certain sub-directory \n",
        "  print( \"Processing the direcotry : \" , subdir , \"\\n\\n\")\n",
        "\n",
        "  for files in os.listdir(subdir) :\n",
        "    try :\n",
        "      name = os.path.join( subdir , files ) # name of the file \n",
        "      if os.path.isfile( name ):\n",
        "        img , predicted = take_photo( name )  # calling take with image location in drive  \n",
        "        if len(predicted) != 0 :\n",
        "          print( \"Actual \" , tag , \"Predicted value \" , predicted )  # printing the predicted value\n",
        "          actual.append(tag) # for debugging \n",
        "          pre.append(  tag if ( tag in predicted ) else predicted[0]  )\n",
        "          print(actual[-1] , pre[-1]) # for debugging \n",
        "          cv2.imwrite( subdir + \"/predicted/\" + files , img  ) \n",
        "        else :\n",
        "          print(\"Model not able to predict for \" , name )\n",
        "    except Exception as err:\n",
        "      # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "      # grant the page permission to access it.\n",
        "      print(str(err))\n",
        "\n",
        "print(actual , pre )\n",
        " "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing the direcotry :  drive/MyDrive/EmotionDetection/Model_Training_Op/images/happy \n",
            "\n",
            "\n",
            "Actual  3 Predicted value  [3, 4]\n",
            "3 3\n",
            "Actual  3 Predicted value  [3, 6]\n",
            "3 3\n",
            "Actual  3 Predicted value  [3]\n",
            "3 3\n",
            "Actual  3 Predicted value  [3, 6]\n",
            "3 3\n",
            "Actual  3 Predicted value  [0]\n",
            "3 0\n",
            "Actual  3 Predicted value  [3]\n",
            "3 3\n",
            "Actual  3 Predicted value  [3]\n",
            "3 3\n",
            "Actual  3 Predicted value  [3]\n",
            "3 3\n",
            "Actual  3 Predicted value  [3]\n",
            "3 3\n",
            "Model not able to predict for  drive/MyDrive/EmotionDetection/Model_Training_Op/images/happy/happy9.jpg\n",
            "Actual  3 Predicted value  [3]\n",
            "3 3\n",
            "Actual  3 Predicted value  [3]\n",
            "3 3\n",
            "Actual  3 Predicted value  [3, 6, 6, 6, 0, 6, 3, 6]\n",
            "3 3\n",
            "Actual  3 Predicted value  [3, 6]\n",
            "3 3\n",
            "Actual  3 Predicted value  [3, 4]\n",
            "3 3\n",
            "Actual  3 Predicted value  [0]\n",
            "3 0\n",
            "Actual  3 Predicted value  [0, 6]\n",
            "3 0\n",
            "Processing the direcotry :  drive/MyDrive/EmotionDetection/Model_Training_Op/images/angry \n",
            "\n",
            "\n",
            "Actual  0 Predicted value  [0]\n",
            "0 0\n",
            "Actual  0 Predicted value  [0]\n",
            "0 0\n",
            "Actual  0 Predicted value  [6]\n",
            "0 6\n",
            "Actual  0 Predicted value  [6]\n",
            "0 6\n",
            "Actual  0 Predicted value  [0]\n",
            "0 0\n",
            "Actual  0 Predicted value  [0]\n",
            "0 0\n",
            "Actual  0 Predicted value  [0]\n",
            "0 0\n",
            "Actual  0 Predicted value  [6, 6]\n",
            "0 6\n",
            "Actual  0 Predicted value  [0]\n",
            "0 0\n",
            "Actual  0 Predicted value  [3]\n",
            "0 3\n",
            "Actual  0 Predicted value  [4]\n",
            "0 4\n",
            "Processing the direcotry :  drive/MyDrive/EmotionDetection/Model_Training_Op/images/sad \n",
            "\n",
            "\n",
            "Actual  4 Predicted value  [4]\n",
            "4 4\n",
            "Actual  4 Predicted value  [4]\n",
            "4 4\n",
            "Actual  4 Predicted value  [4, 6]\n",
            "4 4\n",
            "Actual  4 Predicted value  [6]\n",
            "4 6\n",
            "Model not able to predict for  drive/MyDrive/EmotionDetection/Model_Training_Op/images/sad/sad6.jpg\n",
            "Model not able to predict for  drive/MyDrive/EmotionDetection/Model_Training_Op/images/sad/sad7.png\n",
            "Actual  4 Predicted value  [3]\n",
            "4 3\n",
            "Actual  4 Predicted value  [4]\n",
            "4 4\n",
            "Actual  4 Predicted value  [6]\n",
            "4 6\n",
            "Actual  4 Predicted value  [4]\n",
            "4 4\n",
            "Actual  4 Predicted value  [3]\n",
            "4 3\n",
            "Actual  4 Predicted value  [4]\n",
            "4 4\n",
            "Processing the direcotry :  drive/MyDrive/EmotionDetection/Model_Training_Op/images/neutral \n",
            "\n",
            "\n",
            "Actual  6 Predicted value  [6, 6]\n",
            "6 6\n",
            "Actual  6 Predicted value  [6]\n",
            "6 6\n",
            "Actual  6 Predicted value  [6]\n",
            "6 6\n",
            "Actual  6 Predicted value  [4]\n",
            "6 4\n",
            "Actual  6 Predicted value  [6, 6, 6]\n",
            "6 6\n",
            "Actual  6 Predicted value  [6, 6, 6, 6, 6, 6, 6, 6]\n",
            "6 6\n",
            "Actual  6 Predicted value  [6, 6]\n",
            "6 6\n",
            "Actual  6 Predicted value  [6]\n",
            "6 6\n",
            "Actual  6 Predicted value  [5]\n",
            "6 5\n",
            "Actual  6 Predicted value  [6]\n",
            "6 6\n",
            "Actual  6 Predicted value  [6]\n",
            "6 6\n",
            "Actual  6 Predicted value  [0, 6, 6]\n",
            "6 6\n",
            "Processing the direcotry :  drive/MyDrive/EmotionDetection/Model_Training_Op/images/surprise \n",
            "\n",
            "\n",
            "Actual  5 Predicted value  [6, 6]\n",
            "5 6\n",
            "Actual  5 Predicted value  [6, 5, 6]\n",
            "5 5\n",
            "Actual  5 Predicted value  [5]\n",
            "5 5\n",
            "Actual  5 Predicted value  [5]\n",
            "5 5\n",
            "Actual  5 Predicted value  [5]\n",
            "5 5\n",
            "Actual  5 Predicted value  [5]\n",
            "5 5\n",
            "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5] [3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 6, 6, 0, 0, 0, 6, 0, 3, 4, 4, 4, 4, 6, 3, 4, 6, 4, 3, 4, 6, 6, 6, 4, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 5, 5, 5, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyFYHuxfb-O3",
        "outputId": "09b53d0c-e476-4398-cdec-17257c89b50b"
      },
      "source": [
        "print(actual)\n",
        "print(pre)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5]\n",
            "[3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 6, 6, 0, 0, 0, 6, 0, 3, 4, 4, 4, 4, 6, 3, 4, 6, 4, 3, 4, 6, 6, 6, 4, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 5, 5, 5, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34RqZyl9cWqz"
      },
      "source": [
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt  \n",
        "import itertools \n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkD3r0mOdZZJ"
      },
      "source": [
        "c_matrix = confusion_matrix(y_true = actual , y_pred = pre )"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCJnZqt-dnsN"
      },
      "source": [
        "def plot_confusion_matrix( cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    plt.title(title)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UrxkJ0RebTm"
      },
      "source": [
        "plot_labels = ['angry', 'happy', 'sad', 'surprise', 'neutral']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPUoJFXhekoF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "0d4308bb-c229-4b37-b46a-1c86ab569c73"
      },
      "source": [
        "plot_confusion_matrix( cm = c_matrix , classes = plot_labels , title='Confusion Matrix' )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[ 6  1  1  0  3]\n",
            " [ 3 13  0  0  0]\n",
            " [ 0  2  6  0  2]\n",
            " [ 0  0  0  5  1]\n",
            " [ 0  0  1  1 10]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4IlmbWXKzci",
        "outputId": "e6c417be-6520-42bf-80bc-7d0c797cef47"
      },
      "source": [
        "print(c_matrix)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6  1  1  0  3]\n",
            " [ 3 13  0  0  0]\n",
            " [ 0  2  6  0  2]\n",
            " [ 0  0  0  5  1]\n",
            " [ 0  0  1  1 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9_wh8wNmBuC",
        "outputId": "0bfcf175-572b-44ff-8831-4607f036505b"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "# lambda method for main 4 terms - TP , TN , FP and FN \n",
        "TruePositive = lambda conf_mat : sum( [ conf_mat[i][i] for i in range(len(conf_mat)) ] )\n",
        "TrueNegative = TruePositive   # as both will be the same case \n",
        "FalsePositive = lambda conf_mat : sum( [ conf_mat[i][j] for i in range(len(conf_mat))  for j in range(len(conf_mat)) ] ) - TruePositive(conf_mat)\n",
        "FalseNegative = FalsePositive # as both will be the same cse \n",
        "TotalSample = lambda conf_mat : sum( [ conf_mat[i][j] for i in range(len(conf_mat))  for j in range(len(conf_mat)) ] )\n",
        "\n",
        "\n",
        "\n",
        "# precession - sum of tp accross all class / sum of ( TP and FN across all class)\n",
        "# precession - TP / ( TP + FN )\n",
        "precession = TruePositive(c_matrix) / ( TruePositive(c_matrix) + FalseNegative(c_matrix) )\n",
        "print(\"Precession \" , precession )\n",
        "print( precision_score( actual, pre , average = 'micro' ) )\n",
        "\n",
        "\n",
        "\n",
        "# recall - sum of tp accross all class / sum of ( TP and FN across all class)\n",
        "# recall - TP / ( TP + FN )\n",
        "recall = TruePositive(c_matrix) / ( TruePositive(c_matrix) + FalseNegative(c_matrix) )\n",
        "print(\"Recall \" , precession )\n",
        "print( recall_score( actual, pre , average = 'micro' ) )\n",
        "\n",
        "\n",
        "# F2 score - (5*precession*recall) / (4*precession+recall) \n",
        "f2_score = (5*precession*recall) / (4*precession+recall) \n",
        "print(\"F2 score \" , f2_score )\n",
        "print( fbeta_score(actual, pre , beta = 2.0 , average = 'micro' ) )\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precession  0.7272727272727273\n",
            "0.7272727272727273\n",
            "Recall  0.7272727272727273\n",
            "0.7272727272727273\n",
            "F@ score  0.7272727272727274\n",
            "0.7272727272727274\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}