{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshanChongder/IMAGE-PROCESSING-AND-FACIAL-EMOTION-DETECTION/blob/master/Capture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aexl3mK9zS2H"
      },
      "source": [
        "Importing the dependencies .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnRoMxswSldE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b19d015-55d6-4b81-8c84-f7fe22532841"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj9YcAnsT4B_"
      },
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2 , PIL , io , html , time , os \n",
        "import numpy as np \n",
        "from keras.preprocessing import image\n",
        "from keras.models import model_from_json "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2rHTBKSuHNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09d71d5-fa25-4ed7-cf8f-dc732e23a4cc"
      },
      "source": [
        "#drive/MyDrive/EmotionDetection/Model_Training_Op/24_06_1/model/\n",
        "model = model_from_json( open('drive/MyDrive/EmotionDetection/Model_Training_Op/24_06/model/fer.json','r').read() )\n",
        "# drive/MyDrive/EmotionDetection/Model_Training_Op/24_06_1/model/\n",
        "model.load_weights( 'drive/MyDrive/EmotionDetection/Model_Training_Op/24_06_1/model/fer.h5' )\n",
        "print('The model is been loadded with weights')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model is been loadded with weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09b_0FAnUa9y"
      },
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "  return img\n",
        "\n",
        "\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  bbox_PIL.save(iobuf, format='png') # format bbox into png for return\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))  # format return string\n",
        "\n",
        "  return bbox_bytes\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghUlAJzKSjFT"
      },
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpA68lTrcvZs"
      },
      "source": [
        "#Haar Cascade face detection model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaiBrOlG0reu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fbb3c632-6aa6-4368-8329-03803c37742c"
      },
      "source": [
        "# start streaming video from webcam\n",
        "video_stream() \n",
        "\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "\n",
        "#face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count , plot = 0 , []  \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    \n",
        "    # grayscale image for face detection\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    faces_detected = face_cascade.detectMultiScale(gray_img) \n",
        "    \n",
        "    for (x,y,w,h) in faces_detected:\n",
        "        bbox_array = cv2.rectangle(bbox_array,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "        cropped_gray=gray_img[y:y+w,x:x+h]  # cropping the image \n",
        "        cropped_gray=cv2.resize(cropped_gray,(48,48))\n",
        "        pixels = image.img_to_array(cropped_gray)\n",
        "        pixels = np.expand_dims(pixels, axis = 0)\n",
        "        pixels /= 255\n",
        "\n",
        "        predictions = model.predict(pixels) \n",
        "        #print( predictions )\n",
        "        #find max indexed array\n",
        "        max_index = np.argmax(predictions[0]) \n",
        "        plot.append(max_index)\n",
        "        \n",
        "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "        predicted_emotion = emotions[max_index]\n",
        "\n",
        "        cv2.putText(bbox_array, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv21uGPA5n-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8133bb0d-75b8-4685-f3cb-192d0341c663"
      },
      "source": [
        "print(set(plot))\n",
        "d = {}\n",
        "for i in plot:\n",
        "  if i in d :\n",
        "    d[i]+=1\n",
        "  else :\n",
        "    d[i] = 1\n",
        "print(d)\n",
        "tags , count = ['angry', 'happy', 'sad', 'surprise', 'neutral'] , [] \n",
        "for i in sorted(d.keys()) :\n",
        "  count.append(d[i])\n",
        "print(tags,count)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 3, 4, 5, 6}\n",
            "{6: 39, 3: 21, 5: 20, 0: 42, 4: 3}\n",
            "['angry', 'happy', 'sad', 'surprise', 'neutral'] [42, 21, 3, 20, 39]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "BURqABhN7Ih6",
        "outputId": "2dfc07f5-e83d-4e8f-92b5-d6ac85e10265"
      },
      "source": [
        "# plotting the bar graph \n",
        "import matplotlib.pyplot as plt\n",
        "print(tags,count)\n",
        "plt.xlabel('Emotions')\n",
        "plt.ylabel('Count')\n",
        "plt.bar(tags,count,color = ['red', 'blue', 'orange', 'green', 'cyan'] , width = [0.7]*5 )\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['angry', 'happy', 'sad', 'surprise', 'neutral'] [42, 21, 3, 20, 39]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}